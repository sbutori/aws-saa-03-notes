# Adrian Cantrill's AWS Certified Solutions Architect - Associate (SAA-C03) Course


# INTRODUCTION & SCENARIO

# Public Introduction - No Notes

# Course Resources
Course has GitHub Repository: https://github.com/acantril/aws-sa-associate-saac03
Walked through how to d/l Git to PC and clone repo for access.
To update to latest version: "git pull"

Walked through and recommended VS Studio Code install

# Site Tools & Features

## Quick tour of the learning platform
Products page, Slack channel, free GitHub repo: "Labs" link, mini projects in the GH repo, "More" tab for tech support

# AWS Exams / Certifications

## How to get started
Don't start with the Cloud Practitioner Foundational Cert, start with Associate level SA (Solutions Architect). The content overlaps.
After you finish SA Associate do the Role Based certs, then Specialty certs later. Get SA Professional prior to Specialties certs
- In Associate level, start with 1. SA before SysOps/Developer 2. then Developer Associate 3. then SysOps Associate (Hardest exam of the 3).
- In Professional level, tests are way harder. Longer questions, more questions. 1. Professional SA, 2. DevOps Pro exam

# Scenario - Animals4life

Animal rescue/awareness Org. Global company, 100 staff, 100 remote staff, etc etc. Small data-center is old, and data should be migrated out. 
Badly implemented AWS trial in SYD Region. Isolated Azure/GCP Pilots. All staff uses this infrastructure. Company runs lean but will get new tech
if it helps business. 
- On Premise: 192.168.10.0/24, Class C
- AWS Pilot: 10.0.0.0/16, Class B
- Azure Pilot: 172.31.0.0/16, Class B
Major offices NY, Seattle, London all use Head Office services for data
Field workers on laptop, 3g/4g/ satellite for email/files, chat/planning, research data

## Problems: Hardware failing, datacenter decommissioned in 18months, so business needs to migrate out. New investment needed, not sure if on premise, azure, aws, etc. Previous AWS/Azure attempts didn't pan out. Distance to datacenter is sub-optimal for much of company. Lean/appropriately sized, but trouble with peak traffic. IT team sucks at cloud.

## Ideal Outcomes: 
- Fast performance for all field workers
- Able to deploy into new regions quickly when required
- Low cost and scalable base infrastructure, cost close to 0 as possible while meeting reqs
- Agility - new marketing campaigns, social and progressive applications (IOT, Big Data, etc). Wants to make use of emerging technologies
- Automation - low base staffing costs

## Pay attention to which areas need more information, so you can ask the right questions.

# Connect with other students and your instructor - techstudyslack.com. Make sure you meet people in the industry--50% of jobs aren't posted anywhere.
- No better way to learn tech than help others

# Course upgrades: If you've already bought a course but want a bundle, you'll just have to pay the difference.


# COURSE FUNDAMENTALS AND AWS ACCOUNTS

## AWS Accounts
AWS Accounts are not only required to use AWS services, they are also one of the most important tools available to a solutions architect.
Many students confuse accounts with users inside the accounts. An org may use one account or many thousands. Bigger orgs generally use multiple AWS accounts.

At a high level, AWS Account is a container for Identities (users) (which you log in with) and Resources (which you provision).

When creating an AWS account need need to provide:
- Unique email address (for EACH AWS account); this creates a special type of identity: the account root user
- Provide a payment method, generally a Credit Card (No need to spend: You can choose a Free tier and create a zero-spend budget)

Root Users can only access their own accounts. Initially, it is also the only user. Root user has full control over the one specific AWS account and any resources inside it. Root user CANNOT be restricted in any way. Protect the root username and password.

### Billing 
Credit Card used to open account is the Account Payment Method. Any billable usage is charged to this CC. "Pay-as-you-go" platform. There is a free tier which we use in this course.

### Security
You can create restricted identities/users using Identity and Access Management (IAM): Users, Groups, and Roles can also be created and given FULL or LIMITED permissions. All of these ID's start off with NO access/permissions in the account. The IAM service is Account specific. Cross-account permissions are a possibility, as well (to be covered later).

### Boundary of the Account
AWS accounts are really good at containing what's inside the accounts; bad employee or bad actor, etc. Having separate AWS accounts for different uses (DEV, PROD, etc), you can limit overall damage.

By default, all access to an AWS account is denied except for the root user.

# TIP: Create new accounts for the course, don't use existing AWS accounts. The longer an AWS account exists, the more potential for configuration errors.


## DEMO: Creating the GENERAL AWS Account: https://learn.cantrill.io/courses/1820301/lectures/41301459
1. Create General AWS account (*MANAGEMENT). This account's root user will be what we log in with (root user = account specific).
2. Add root user MFA for security.
3. Create a Budget to protect against unintended costs.
4. Create an IAM user, IAMADMIN. Give permissions. Then we'll use this ID for the course.
5. Create a second accound, Production. Will also have IAMADMIN user.

## TIP: using one email for multiple accounts with Gmail. AWS accounts should be viewed as disposable, create as many as you need. Create a new account for each course. 
### TIP Example: email is catguy@gmail.com. You can use + sign in email address to create 'unique' email addresses. Ex: catguy+AWSAccount1@gmail.com, catguy+AWSAccount2@gmail.com, etc etc. This is called a Dynamic Alias.

Choose free tier AWS account after providing all account setup info (unique email, CC, verification.

Complete the prompted steps. Account will now be created.

### Account
- Always a good idea to update Alternate Contacts
- IAM User and Role Access to Billing Information, click "Edit", check Activate IAM Access
-- If this IAM box isn't checked, even an IAM ID will full admin permissions wouldn't be able to access the billing console

### Multi-Factor Authentication (MFA)
- Username and PW is step one
- MFA makes things more secure with OTP

Definition: Factors - Different pieces of evidence which prove identity

4 Common Factors:
- Knowledge (username / PW)
- Possession (debit card, MFA device, MFA app, etc)
- Inherent - Something you are: fingerprint, biometrics, etc.
- Location - Physical location, which network (corp or wifi)

More factors means more security and harder to fake. Also means less convenient. We're trying to strike a balance between security and convenience.

With AWS: 1. first, username and PW 2. MFA OTP (physical MFA or virtual via app ie. Google Authenticator)

To Activate MFA for a specific ID, like Root user, you activate MFA for that user. AWS generates secret key and other associated information (user it links to, service). All this information use all this information together to generate a QR code. Scan code using MFA app

### Securing an AWS Account
Attach MFA device to Root user.

In AWS Console... Account > Security Credentials to IAM console > locate "Assign MFA Device", follow steps.
- Log Out and test MFA login.

# REMEMBER: When setting up a new AWS account / Identity, you need to add another entry within your OTP application.

By end of this course, you should have a total of 4 virtual MFA's configured.

### Creating a Budget
Understand Free Tier and set up a budget.

AWS Free Tier: https://aws.amazon.com/free/
- Details allocations of free resources

Spend Details: Account > Billing Dashboard > click "Bills" (for spend details)

Billing Notification Preferences: Click "Billing Preferences" > check all boxes within "Invoice delivery preferences" and "Alert preferences" and Update

Create Cost Budgets: click "Budgets" > select Use a Template > select an appropriate option based on monthly spend budget (select Zero spend budget) > Budget Name "Monthly Zero Budget", enter Email Recipients for alerts ([EMAIL]+trainingawsgeneral@gmail.com) > click "Create Budget"
-- Budgets allow you to monitor spend and configure alerts when hitting spend targets

### Creating the Production Account
After creating General AWS account, we now need to create multiple AWS accounts and connect them with an AWS Organization.

#### Create Production AWS Account
Steps:
1. First, decide on email address to use [EMAIL]+trainingawsproduction1@gmail.com
2. Credit Card
3. Support Plan (Free Tier)
4. Secure AWS account with MFA to Root user of Production Account
5. Billing Preferences, check the boxes, adding email address for alerts
6. Create budget (Zero Spend Template)
7. Enable IAM User & Role Access to Billing (in Accounts)
8. Optional: Update alternate contacts in Account

### IAM (Identity and Access Management) Basics
We first need to understand the identity situation. Accounts created have Root user will full access. AWS account and Root user can be thought of as the same thing. 

Generally, you want to give access to other people in the companies, but with restricted access -- ONLY GIVE THEM PERMISSIONS REQUIRED TO DO A JOB, called "Least Priveleged Access". 

EXAM: IAM is a globally resilient service, so any data is always secure across all AWS regions.

Any IAM's in an account are completely separate from any other accounts. IAM as a service can do as much as the Root user if given all permissions, exception being some billing stuff (but that can be activated).

Inside IAM, you can create multiple identities. 

IAM let's you create 3 types of identity objects:
- User
- Group
- Role

Users: Humans or applications that need access to your AWS account. An application that does backups of the account may also be an IAM user.

Group: Collections of related users. All dev team users, finance, HR, etc.

Roles: Can be used by AWS Services or if you want to grant external access to your account. Used to grant access to services in your account to an uncertain number of entities. EX: If you want all EC2 instances in your account to access the Simple Storage Service, you can create a role which grants access and allow instances to use that role. 

TIP: ROLES used when the number of entities needing access is *uncertain*.

### IAM Policy or Policy Document
Objects or documents to be used to Allow or Deny access to AWS services, only when attached to users, groups, or roles.

### High Level IAM
IAM has 3 main jobs:
1. IDP (ID Provider): Manages identities
2. Authentication Process: Authenticates identities (when anyone makes request to AWS, they're known as a Security Principle--they must prove their identity)
3. Authorization: Allowed or Denied access to resources. This is based on Policies associated with the identity that is authenticated with.

### Other IAM Key Points
- No cost for IAM
- Global service / Global Resilience (copes with failure of large parts of the AWS system)
- IAM only controls what its identities can do. Allow or Deny identities in account
- No direct control on external accounts or users. It only controls local accounts or users
- Identity federation (to be covered later) and MFA

Next, we'll create an IAM account with full permissions to take the place of the Root user. Root users should generally only be used to create an account. Afterward, best practice is to utilize an IAM User rather than account root user. We'll use this IAM user to create new identities with less permissions (only enough for the user to do a certain task)

## DEMO Adding an IAM Admin to GENERAL ACCOUNT
Set up AIM ID with Admin permissions

Search "IAM" > IAM Dashboard

To sign on with IAM identities, use sign-in URL: http://[account-id].signin.aws.amazon.com/console. 
-- To make friendlier URL, set alias.

### To set alias, make it globablly unique. 
1. Within IAM Dashboard, find right-side AWS Account info, find "Account Alias", click "Create".
- Must be a globablly unique ID. I am using "ta-cantrill-training-aws-general"
-- Now URL is https://ta-cantrill-training-aws-general.signin.aws.amazon.com/console

### Create IAM Admin ID
IAM Dashboard > left sidebar "Users" > Create user "iamadmin"
- Give Access to Console
- Create an IAM user (2nd option, 1st option to be covered later)
- Custom PW
- Give admin permissions "Attach policies directly" > check "AdministratorAccess"
- Create user
- Test login
- Confirm login with profile dropdown that will show account name
- Secure admin account with OTP > Security Credentials > Assign MFA
- Log out and test OTP

## DEMO Adding an IAM Admin to PRODUCTION ACCOUNT
Same as previous section.

## IAM Access Keys
Access AWS via command line or APIs. This is done using IAM access keys.

### IAM Access Keys
- long term credential (don't change or rotate regularly)
- IAM user has 1 username and 1 PW (cannot have more than 1). Password on IAM user is actually optional.
- Credential Leak: If someone knows your username (public) and password (private)
- Unlike username/PW, IAM user can have TWO access keys
- Access key actions: create, delete, made inactive, made active. Default: Active state
- Access keys are formed from two parts: 
1) Access Key ID 
2) Secret Access Key
--AWS provides both when key is created.
- Once the key is generated, you CANNOT access the Secret Access Key part again
- If leaked/lost, you need to delete ID and Secret Access Key and recreate completely
- If made inactive or deleted, CLI will stop working until re-active or new key is created
- Rotating Access Keys: delete old one make new one and replace old one
- NOT recommended: Don't give Root user Access Keys
- IAM Roles DO NOT use access keys

## DEMO Creating Access Keys and Setting Up AWS CLI v2 Tools

Once logged in with Admin user:
IAM Dropdown > Security Credentials > scroll down to "Create Access Key", click > Command Line Interface (CLI) > check box at bottom > Next > Set Decription Tag > "Create Access Key"

Once Access Key is created, you can use Actions dropdown to Deactivate, Activate, and Delete. If you ever lose access to a key, you need to deactivate & delete it, then create a new one.

### Download AWS CLI v2 
AWS CLI v2 (Windows) Installation - https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-windows.html

AWS CLI v2 (macOS) Installation - https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-mac.html

AWS CLI v2 (Linux) Installation - https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-linux.html

### Configure CLI
Configure a set of credentials which CLI will use to communicate with AWS. We will use the General IAMADMIN user for this one.

COMMAND: 'aws configure': configures default profile for CLI
COMMAND: 'aws configure --profile iamadmin-general' / 'aws configure --profile iamadmin-production': named profile for CLI

Upon entering the above Command:
- AWS Access Key ID
- AWS Secret Key
- Default Region Name: us-east-1
- Default output format (press Enter with blank field for default)

Test that this is successful with COMMAND 'aws s3 ls --profile [CLI profile name]'. This will error first as we need to specify named profile:
'aws s3 ls --profile iamadmin-general', which will currently return a blank string as there are no s3 buckets.

#### Configure for Production
COMMAND: 'aws configure --profile iamadmin-production'
COMMAND to test: 'aws s3 ls --profile iamadmin-production'

SECURITY REMINDER: Never share your SECRET KEY. If leaked, delete and create new set of keys and re-configure in CLI

TIP: If after you Configure CLI with credentials, you can delete the credential files (CSVs)


## AWS FUNDAMENTALS

### AWS Public VS Private Services
Architecture of both Public/Private Services. "Private"/"Public" refer to networking only. Private runs within VPC, Public is s3
- Both require Permissions / Configuration
3 Zones:
- 1. Public Internet Zone
- 2. AWS Private Zone: VPC's are Virtual Private Clouds. VPCs are isolated unless configured otherwise. Can attach IGW (internet gateway) for access to internet
- 3. Third zone, AWS Public Zone (runs between Public and Private zones). It's a network connected to the Public internet

#### AWS Public Service: What is true of an AWS Public Service? 1. Located in the AWS Public Zone 2. Anyone can connect, but permissions are required to access the service
#### AWS Private Service: What is true of an AWS Private Service? 1. Located in a VPC 2. Accessibly from the VPC it is located in 3. Accessible from other VPCs or on-premise networks as long as private networking is configured


### AWS Global Infrastructure
AWS have created a global public cloud platform which consists of isolated 'regions' connected together by high speed global networking.

Two types of Deployment at global level: 1) AWS Regions, 2) AWS Edge Locations (doesn't directly map to continent or country)
#### AWS Region: Geographically spread. Full compute, storage, DB, AI, Analytics
-- Three main benefits
--- 1. Geographically separate for physical reslience. Isolated Fault Domain
--- 2. Geopolitical Separation. Different governance
--- 3. Location Control. Performance
-- Inside regions: You can use Region Code or Region Name. Eg Sygney Australia. RC: ap-southeast-2, RN: Asia Pacific (Sydney)

#### AWS Availability Zone
Located inside regions. Eg. for Sydney AU: ap-southeast-2a, ap-southeast-2b, ap-southeast-2c. If an issue is only in 1 availability zone (AZ), you'll still have functioning services in the other AZs

#### AWS Edge Location: Local distribution points closest to user. Content distribution services, edge computing. Eg. Netflix storing content close as possible to user. Edge locations for fast/efficient data transfer because they're closer to the user. Uses CloudFront

#### AWS AZ VS Edge Location
An Availability Zone is an isolated location within an AWS region. An edge location delivers cached content to the closest location to reduce latency for users.

NOTE: Visit: infrastructure.aws

Service Resilience 
- Globally Resilient: Operates globally with a single DB and replicated across multiple regions. World would need to fail to experience a full outage here. Eg. IAM
- Regionally Resilient: Operate in single region with one dataset in a region. Replicate data to AZs for resilience.
- Availability Zone Resilient: Prone to failure as they have less redundancies.

### AWS Default Virtual Private Cloud (VPC)
A Virtual Network inside AWS. VPCs are regional services; regionally resilient. They operate from multiple AZ's in a region. 
- A VPC is 1 account and 1 region, cann't be spread across multiple accounts/regions
- Private and isolated unless configured otherwise
- Default VPC (max 1 per region, pre-configured) and Custom VPCs (can have many)
- Used to connect AWS private networks to on-premise network. Or connecting during multi-cloud deployments

#### Default VPC
There can only be one default VPC per region, and they can be deleted and recreated from the console UI. Unless configured otherwise, VPC is entirely private/isolated. 
- VPC CIDR: Start and end range of IP addresses VPC can use. If anything needs (and is allowed to) communicate with VPC, it needs to communicate to the VPC CIDR
- Default VPC only gets 1 CIDR IP range. Can't change it.
- Default provides Internet Gateway (IGW), Security Group, and NACL
- VPC can be subdivided into subnetworks. Each subnet in VPC is located in one AZ. Default VPC has one subnet in each AZ by default
-- Each subnet uses part of the VPC CIDR range
-- Default VPC CIDR: always 172.31.0.0/16
-- Assigns public IPv4 addresses
--- /20 subnet in each AZ in the region. The higher the /#, the smaller the network. /17 is half the size of /16

QUIZ: How many subnets are in a default VPC? Default VPCs always have the same IP range and same '1 subnet per AZ' architecture. # Subnets = # AZ's in region

##### Default VPC - Create / Delete

To Locate: AWS Dashboard > Search "VPC" > Your VPCs

To Delete: check Default VPC > actions dropdown "Delete" > follow prompt

To Create Default VPC: If you've deleted Default VPC. In Your VPCs > Actions dropdown > Create Default VPC

### Elastic Compute Cloud (EC2) Basics
Basically the default compute service of AWS. It allows you to provision Virtual Machines known as Instances with resources you select and an operating system of your choosing.
- EC2 is IaaS, Infrastructure-as-a-service. Unit of consumption is the Instance. Instance is a configured O/S
- Private service by default, uses VPC networking
- Public access must be configured. The VPC it's running within must support Public access (if using custom VPC, you need to configure this in VPC)
- EC2 is AZ Resilient
- When launching an Instance, you can choose size and capability
- On-Demand Billing, by second or hour
- Storage Types: Local on-host storage, or network storage via Elastic Block Store (EBS)

#### EC2 instance has attribute called State
States to Know: Running, Stopped, Terminated
- When instance is launched and provisioned, it moves to Running. If instance is shut down, it is Stopped
- Instance can be terminated, but this cannot be reversed

These States influence the charges for an instance. 
- Stopped instance uses less resources, therefore less expensive. You won't be charged for "running" the instance
- Regardless of Running or Stopped, storage is still allocated and you'll still be charged for EBS storage even if instance is stopped
- To guarantee 0 cost on instance, you must Terminate. Termination is irreversible

#### Components for instance charge: running the instance, storage the instance uses, extras for any commercial software the instance is launched with

#### AMI: Amazon Machine Image
Image of an EC2 instance
- Can create EC2 instance
- Can be created FROM an EC2 instance

##### AMI contains attached permissions. Controls which accts can/can't use AMI:
- Public Type - Everyone allowed
- Owner - Implicit Allow
- Explicit - Allow specific AWS accounts


##### AMI includes the following:
- One or more Amazon Elastic Block Store (Amazon EBS) snapshots, or, for instance-store-backed AMIs, a template for the root volume of the instance (for example, an operating system, an application server, and applications).
- Launch permissions that control which AWS accounts can use the AMI to launch instances.
- A block device mapping that specifies the volumes to attach to the instance when it's launched.

##### NOT stored in AMI:
- Instance Settings
- Network Settings

Root Volume: AMI contains boot volume of instance, boots O/S

Block Device Mapping: Config that links volumes that AMI has and how they're presented to O/S. Ie. Which is boot volume, which is data volume

#### Connecting to EC2: 
- Connect to Windows instances using RDP (Remote Desktop Protocol), port 3389
- Connect to Linux distros use SSH protocol, port 22. Log in using SSH key pair

### DEMO: Create an EC2 Instance
https://learn.cantrill.io/courses/1820301/lectures/41301621
1. Create SSH Key Pair: Navigate to EC2 Console (search bar) > left sidebar > Network & Security > Key Pairs) > click "Create Key Pair"
- Note: For creating key pair, Private key file format choises are .pem and .ppk. For MacOS/Linux, always use .pem, if using modern Windows you can choose .pem. Older Windows or Putty terminal app, choose .ppk
2. Configure: Left sidebar "Instances" > click "Launch Instances" > select O/S (Amazon Linux) > select keypair login (A4L) > Network Settings: select Create Security Group > name/description "MyFirstInstanceSG" > leave Inbound security groups rules as defaults > Launch EC2 Instance

### DEMO: Connect to Terminal of an EC2 Instance
1. In EC2 Dashboard, Right Click your EC2 instance, select "Connect" > SSH Client
2. Open your local Terminal / Command Prompt and change directories to wherever your SSH private file key is (likely Downloads, it's a .pem file created previously)
3. Copy the command at the bottom of the SSH Client tab "ssh -i "A4L.pem" ec2-user@ec2-54-89-175-122.compute-1.amazonaws.com", verify fingerprint with "yes"
- Note: If using MacOS/Linux and "Permission Denied": paste in terminal "chmod 400 A4L.pem"
- More key file permissions help: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/connection-prereqs.html#connection-prereqs-private-key

### S3 Basics: Simple Storage Service
Global Storage Platform - regional based/resilient. Access from anywhere.
- Public service, can cope with unlimited data & multi-users
- Perfect for hosting large amounts of data
- Economical and accessed via UI/CLI/API/HTTP

#### S3 Delivers 2 things: Objects and Buckets

##### S3 Objects
What is an Object? An object is a file and any optional metadata that describes the file.

Two components and some associated metadata: 
1. Object Key. identifies object in a bucket
2. Value. data or contents of the object. Object size can range from 0 bytes to 5 terabytes (TB) in size.
Metadata: Version ID, Metadata, access control, subresources

NOTE: S3 = Default Storage Service in AWS

##### S3 Buckets (Simple Storage Service)
Containers created in a specific AWS region; default place to go to in order to configure S3
- Data inside a bucket has a primary home region. Never leaves this region unless configured to do so
- Blast radius of a failure is limited to a region
- Buckets can hold an unlimited number of objects; infinitely scalable
- S3 bucket has no complex structure; flat-structure; everything stored at same level; all stored at Root level (if you list out on Command, it'll look like there are folders, but there aren't Eg. /old/photo1.jpg). Folders are called 'prefixes' in S3.


# EXAM: Bucket name must be Globally Unique. Error where you can't create a bucket? Prolly not a unique name

# EXAM: More bucket name restrictions: 3-63 characters, all lowercase, no underscores, not formatted like IP addresses

# EXAM: Bucket limits: soft limit of 100 buckets per AWS account, hard limit of 1000 buckets (hard limit increased by connecting with Support). If you have more than 1000 users, you can't use 1 bucket per user, but you can use prefixes within a bucket to let multiple users use one bucket.

# EXAM: Unlimited Objects in a bucket, ranging from 0 bytes to 5TB in size

# EXAM: Object Structure: Key = Name, Value = Data

#### S3 Patterns and Anti-Patterns
- S3 is an Object Store system, NOT File System and NOT Block System
- S3 has no File System, it's flat. It's not Block storage, so you can't mount it as K:\ or /images
- Great for 'offload'
- S3 should be your default INPUT and/or OUTPUT to MANY AWS products

# EXAM: Where to store data in AWS? S3 should be default answer 

# QUIZ: What is true of Simple Storage Service (S3)
- S3 is an AWS Public Service
- S3 is an Ojbect Storage System
- Buckets can store an unlimited amount of data

### DEMO: Creating an S3 Bucket
Create, interact with bucket, upload to bucket, interact with uploaded objects
- As S3 is Global, you can't select a Region in advance

STEPS: Move to S3 Console > click 'Create bucket' > name 'koalacampaign987654123' (must be globally unique) > select Region (default N.VA) > untick "Block *all* Public Access (this just enables you to Enable public access later) > click "Create Bucket" 

#### Amazon Resource Name (ARN): All resources in AWS have a unique identifier, the ARN. 
To see bucket ARN, Amazon S3 > Buckets > click the bucket you want > 'Properties' tab > Amazon Resource Name 

#### DEMO: Upload files to Bucket
Amazon S3 > Buckets > click the bucket you want > Objects, click Upload > Select Files > Use default settings > click Upload
- Now, you'll see these files in the Object tab

Note on creating a folder: it doesn't actually create a folder, it creates an object that appears to be a folder. They are just emulated using prefixes Eg. archive/koalazzz.jpg -> Not actually a file, but named to look like it
- Without versioning enabled, same name files can overwrite each other. With Versioning, they can't

#### DEMO: Delete Buckets in S3
Two step process:
1. Empty the bucket > select Bucket, click Empty
2. Re-select Bucket, click Delete

### CloudFormation (CFN) Basics
A tool which lets you create, update, delete infrastructure in AWS using Templates
- At its base, CFN uses templates. Can create/update/delete templates
- Template written in YAML or JSON

From the Documentation: AWS CloudFormation is a service that helps you model and set up your AWS resources so that you can spend less time managing those resources and more time focusing on your applications that run in AWS. You create a template that describes all the AWS resources that you want (like Amazon EC2 instances or Amazon RDS DB instances), and CloudFormation takes care of provisioning and configuring those resources for you

#### What makes a template? Components:
- All templates have a list of resources. This is the only mandatory item 
- Description. Free text field for the author to provide details on template. (If you have AWSTemplateFormatVersion, Description MUST follow it in YAML/JSON
- Metadata. Can control the UI (groupings, order, labels, descriptions), as well as other things (to be covered later)
- Parameters. Value parameters, default values, etc.
- Mappings. Create lookup tables.
- Conditions. Allows decision making in the template. Step 1 create condition, Step 2 use condition 
- Outputs. Once template is finished it can present outputs like admin or setup adddress, instance ID

#### How does CFN use Templates?
Eg. Template that creates EC2 resource. Resources defined in CFN Templates are called Logical Resources. 
- When template is given to CFN, CFN creates a stack which is a living and active representation of a Template. Stack is created with CFN does something with a template.
- For any logical resources in the stack, CFN makes a corresponding physical resourse in your AWS account. It's CFNs job to keep logical and physical resources in sync. Physical resource: A resource created by creating a CloudFormation Stack
- If you delete a CFN Stack, its logical resources are deleted and CFN subsequently deletes the physical resources

# EXAM: In a CFN Template, if you have the AWSTemplateFormatVersion item, the Description MUST follow directly after in your YAML/JSON template file

### DEMO: Simple Automation w/ CFN; Creating EC2 with CFN

"CloudFormation" or CFN in Search > click "Create Stack" > Template is ready > Upload a Template File > use Demo file (ec2instance.yaml) > click "Next" > Name: "cnfdemo1" > leave the rest default > "Next" > skip config "Next" > Review cfndemo1: Capabilities, check the box 
- Template auto-creates an s3 bucket when you upload a Template
- YAML file: 
-- LatestAmiID: Instead of giving latest AMI ID, you can make Type a "latest version" AMI
-- CloudFormation Functions are used within YAML Outputs to get values like InstanceID, Availability Zone (AZ), Public IP of EC2, etc. Eg. !Ref, !GetAtt
-- Resources Component is the main one in the file. In this temmplate, an instance role and instance role profile are being created (SessionManagerRole, SessionManagerInstanceProfile) -- covered later. 
-- Also being created in the Resources portion of the template: EC2 instance, InstanceSecurityGroup. Port 22 (SSH)/Port 80 (HTTP)
-- Resources: EC2Instance: Properties: InstanceType: "t2.micro" -- Free tier elligible
- After Submitting stack to be created, you'll see that each Resource being created is done so by an Event, "CREATE_IN_PROGRESS", "CREATE_COMPLETE". This whole process takes some time before all of cnfdemo1 is showing CREATE_COMPLETE

#### EC2 Session Manager: EC2 Dashboard > Connect to Instance > Session Manager
- No need to SSH in now
- Two logical resources in YAML template configure this ability

## CloudWatch Basics
CloudWatch is a core supporting service within AWS which provides metric, log and event management services. Collects / manages operational data on your behalf.

### Three jobs:
1. Metrics. AWS Products, Apps, on-premises. Some metrics require extra installed CloudWatch Agent
2. CloudWatch Logs. AWS Products, Apps, on-premises. Almost anything logged can be ingested by Logs
3. CloudWatch Events. AWS Services & Schedules. If an AWS service does something, this will generate an event that can perform another action. Or you can set up a chrono-repeating event through here.

### Core Concepts
- Namespace: Container for monitoring data. There is a naming ruleset for naming. All AWS data foes into a special namespace AWS/[service]
- Metric: Collection of related data points in a time-ordered structure
- Datapoints: A single unit of a metric; consists of timestamp and a value
- Dimensions: Generally, a metric is a collection (Eg. CPU utilization comes from all EC2 instances, not just one). You can use dimensions to single out resources to see their individual metrics. "Separate datapoints for different things or perspectives within the same metric"
- Alarms: Taking actions based on metrics. States: OK or ALARM (ALARM can be SNS Notification or Action), and INSUFFICIENT DATA (when there's not yet enough data)

## DEMO: Monitoring with CloudWatch
https://learn.cantrill.io/courses/1820301/lectures/41301629
1. Create EC2 Instance: Nav to EC2 service > Launch Instance Defaults for all, but you can pay to Enable Detailed CloudWatch Monitoring
2. Create CloudWatch alarm: Nav to CloudWatch dashboard > All Alarms > Create Alarm
3. Select Metric > EC2 > Browse Tab (make sure you know last 4 of Instance ID number) > Last 4 of ID number, check box for CPUUTilization metric
4. Metrics / Contitions: Conditions: Static, Whenever CPU Util is Greater/Equal 15% > "Next" > Remove Notification > Alarm Name "cloudwatchtestHIGHCPU" > Next/Create Alarm
5. Back to EC2, connect to EC2 with Instance Connect
6. Need to install Stress app > command: sudo yum install stress -y
7. Stress Test: command: stress -c 1 -t 3600. Make sure CloudWatch alarm is OK status before entering this command. 
8. Clean up: Delete CloudWatch Alarm and Terminate EC2 instance. Delete EC2 Security Group 

Detailed CloudWatch Monitoring: Enables you to monitor, collect, and analyze metrics about your instances through Amazon CloudWatch. Additional charges apply if enabled. If no value is specified the value of the source template will still be used. If the template value is not specified then the default API value will be used.

## Shared Responsibility Model
Vendor and User shared responsibilities. This applies from a security perspective so you know which elements you and the vendor manage.
- Customer is responsible for security 'in' the cloud: client-side data encryption, server-side encryption, networking traffic protection, O/S, platform, IAM, apps
- AWS responsible for security 'of' the cloud 

## High-Availability (HA) vs Fault-Tolerance (FT) vs Disaster Recovery (DR)
### High-Availablily - Aims to ensure an agreed level of operational performance, usually uptime, for a higher than normal period. Doesn't aim to stop failure, but online and providing services as often as possible. Fix should be as quick as possible, often with automation to bring systems back into service quickly; maximizing a system's online time.
- System availability is in the form of percentage uptime. Three 9's -- Up 99.9% of the time==8.77 hours/year downtime. Five 9's==5.26 minutes/year down time
- Costs required to implement: design decisions and automation
### Fault Tolerance - The property that enables a system to continue operating properly in the event of the failure of some (one or more faults within) of its components. Fault tolerance systems work through failure with no disruption; operating through failure.
- Cost of fault tolerance can be expensive because of redundancies and failure toleration via duplicate system components
- Example: Plane operates with Fault Tolerance (more engines, electronic systems etc); can't tolerate failure in flight
### Disaster Recovery - Post-disaster recovery plan. A set of policies, tools, and procedures to enable recovery or continuation of vital technology infrastructure and systems following a natural or human-induced disaster. When disaster occurs, you want to avoiding losing irreplaceable items.

## Route53 (R53) Fundamentals
AWS's managed DNS product. Global service, single database; no need to pick region in console UI. Globally resilient.

### R53: Two main services:
1. Register Domains
2. Host Zones... managed nameserves

### R53: Architecture
Register domains. To do this, it has relationships with all major domain registries (.com, .io, .net, etc)
1. Check if domain available 2. Zone File created for registering domain (DNS DB for domain) 3. Allocates managed nameservers for this zone (usually 4) 4. get nameserver records added to top level domain zone

### R53: Zones
DNS Zones and Hosting for those zones. Hosted zone created if domain available (and allocates 4 NS's to host zone). HZ can be Public, Private (linked to VPCs, for sensitive DNS records). Hosted Zones stores records (recordsets).

## DEMO: R53 Register Domain - animals4life.org
Search / Nav to R53 console > Registered Domains > click "Register Domains" > Search for domain > Select domain you want > Proceed to Checkout (choose duration, auto-renew) > fill out Contact Info > Pricing (up front cost + monthly hosted fee) > click "Submit" > await domain registry
- Transfer Lock: Security feature, domain can't be transferred away from R53 without disabling this lock
- If you delete and recreate HZ, you'll be allocated 4 new Name Servers (would need to update some stuff if you weren't using R5#)

## DNS Record Types
- Nameserver Records (NS). Allows delegation to occur in DNS. Eg. .com zone
- A Records / AAAA Records. Map host names to IP addresses. A record = IPv4, AAAA = IPv6
- CNAME Record. Canconical name. Let's you create equivalent of DNS shortcuts; host-to-host records. CNAMEs reduce admin overhead. 
- MX Record. For email. How a server can find the mail server (SMTP) for a specific domain.
- TXT Records. Add arbitrary text to a domain; add additional functionality. Eg. Prove domain ownership. 

EXAM: CNAMEs cannot point directly at an IP address, only other names.

QUIZ: How many DNS Root Servers Exist? 13
QUIZ: Who managers DNS Root Servers? 12 Large Organizations
QUIZ: Who managers DNS Root Zone? IANA
QUIZ: A Record = IPv4, AAAA Record = IPv6
QUIZ: Which DNS Record type is how the root zone delegates control of .org to the .org registry
QUIZ: Which type of organisation maintains the zones for a TLD (e.g .ORG)? Registry
QUIZ: Which type of organisation has relationships with the .org TLD zone manager allowing domain registration? Registrar

### TTL - Time To Live
Numeric value that can be set on DNS records. Getting result from authoritative source is an authoritative answer. If a 3600 TTL value is set, results of query are stored in resolver server for 3600 seconds (1 hour), creating a non-authoritative answer for delivery -- during this time, another query would receive this cached non-authoritative answer.
- Low value means more queries against your server. High value less queries but less control
- TIP: If doing any work to change DNS values, it's recommended that you lower the TTL value in advance (days/weeks in advance)

## IAM Identity Policies
Policies attached to identities in AWS. 
1. Understand their architecture 2. Gain ability to read/understand a policy 3. Learn to read/write your own

IAM Policy is a set of security statements to AWS, granting or denying product/features. 
- IAM Identity Policy Document: 1 or more statements, created using JSON
-- Statement Id or Sid: Let's you identify a statement and what it does
-- Action: Can be specific individual action, a wild card, or list of multiple independent actions
-- Resources: Wild cards, lists of individual resources (using ARN name)
-- Effect: Allow or Deny

Action and Resource within IAM Policy must match for statement to execute.

### How to Handle Overlap Type Situations
Priorities:
1. Explicit DENY: Overrules everything.
2. Explicit ALLOW: Allows access to all actions on any S3 resource (overrules all but Explicit DENY).
3. Default DENY (Implicit): No explicit DENY or ALLOW, so this takes effect. IAM ID's are generally restricted access by default.
- DENY, ALLOW, DENY

### Two types of Policies
- Inline Policies - JSON policies applied to each IAM account individually. (Manually applying policies to each Identity)
- Managed Policies - Created as their own object. You can attach this policy to more than one identity. Best for Common Access Rights
-- Reusable
-- Low Management Overhead
When to use Inline Policies? For Special or exceptional Allows or Deny's

## IAM Users and ARNs (Amazon Resource Name)
### IAM Users: An identity used for anything requiring long-term AWS access eg. Humans, apps, service accounts. If you can picture one thing; named thing, 99% of the time use IAM
- Starts with the principal; an entity trying to access AWS account (ppl, svc, group of  these_
- Authenticate principal. Principal needs to prove identity against IAM (using Username/PW (humans usually) or Access Keys (app or human in CLI))
- Principal becomes Authenticated Identity
- Authorization for actions via IAM Policy (statements)

### ARN (Amazon Resource Name):
Uniquely identify resources within any AWS accounts. ARNs are used in IAM policies and have a defined format

### ARN Format
arn:partition:service:region:account-id:resource-id
arn:partition:service:region:account-id:resource-type/resource-id
arn:partition:service:region:account-id:resource-type:resource-id

Note: s3 is globally unique, so no need to specify region...
arn:aws:s3:::catgifs -> references s3 bucket ITSELF
arn:aws:s3:::catgifs/* -> references objects IN the bucket (thse two ARNs do not overlap)

# EXAM: MAX 5,000 IAM Users per account
# EXAM: IAM User can be a member of 10 groups maximum
System with more than 5,000 identities? Can't use IAM user for each identity. IAM Roles & Identity Federation fixes this (more later)

## DEMO - Simple Identity Permissions in AWS
Assign some permissions to an IAM identity
- 1-click deployment https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/create/review?templateURL=https://learn-cantrill-labs.s3.amazonaws.com/awscoursedemos/0052-aws-mixed-iam-simplepermissions/demo_cfn.yaml&stackName=IAM
-- Create IAM user Sally and two s3 buckets

IAM PW - Min. 8 characters. Uppercase, lowercase, numbers

Steps:
1. open first link, create PW, create stack
2. Login to new IAM Sally with incognito window, change PW, check ec2 and s3 that the permissions are limited
3. Using the lesson's attached .zip, open s3_fulladmin.json and copy the code to clipboard
4. In ADMIN account > IAM dashboard > User: Sally > Permissions > "Add permissions" > Create inline policy > JSON tab, paste copied text > name "s3admininline" and click "Create policy"
5. In s3, you can prove permissions by uploading merlin/thor.jpg through Sally IAM account

### DEMO - Delete all CFN / IAM info above
1. Delete Managed Policy: IAM > Users > Sally > Permissions > remove "AllsAllS3ExceptCats"
2. s3 > select "catpics"/"animalpics" buckets > click "Empty" > type "permanently delete", submit
3. CFN > Stacks > Delete Stack. NOTE: If you don't see this stack, check your region to make sure youre in N.Virginia

## IAM Groups
IAM groups are containers for IAM users. Makes managing IAM users easier.
- Groups can have both Inline and Managed policies attached
- Soft limit: 300 Groups per account (you can get Support to increase this)
- Groups are NOT a True Identity; they can't be referenced as a PRINCIPAL in a policy (you can grant access to users, not groups)

EXAM: You can't login to IAM Groups; no credentials/login of their own
EXAM: IAM User can be a member of up to 10 IAM Groups (hard limit)
EXAM: AWS Account has a 5,000 IAM user limit (hard limit)
- There is no effective limit for the number of Users in a single IAM Group
EXAM: There is no "All Members" group by default. In IAM, you could create and add all Users to a group
EXAM: Groups CANNOT have nesting. No Groups within Groups
EXAM: Groups are NOT a True Identity; they can't be referenced as a PRINCIPAL in a policy (you can grant access to users, not groups)

Eg. If Sally is a part of 2 IAM Groups, each with an attached policy, and she has an attached policy, she has 3 policies which become Merged Policies
- For figuring out overlapping, combined all policies and tally Allows/Deny's and undergo the same DENY-ALLOW-DENY pattern

### Resource Policy: Controls access to a specific resource, allowing/denying identities to access that bucket. Does this by referencing this ID's with ARNs

## DEMO - Permissions control using IAM Groups
How groups can be used to hold permissions for group members

